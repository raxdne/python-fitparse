#!/usr/bin/env python

import sys

import argparse
import codecs
import datetime
import itertools
import json
import os.path
import types
import array

import numpy as np

import fitparse

t_c = 60
hr_threshold_up   = 170
hr_threshold_down = 165
hr_threshold_break = 120

stat_hr = []
stat_intervals = []
stat_hr_intervals = []
stat_hr_breaks = []
stat_speed = []


def format_csv(num, message, options):

    s = [str(num)]
    if message.name == 'record':
        if options.with_defs:
            s.append(' [{}]'.format(message.type))

        if message.type == 'data':
            for field_data in message:
                if field_data.name == 'timestamp':
                    #t = time.strptime(field_data.value, "%Y-%m-%D %H:%M:%S")
                    t = field_data.value.time()
                    s.append("{}".format(t.hour * 3600 + t.minute * 60 + t.second))
                    #s.append(t.isoformat())
                else:
                    s.append(str(field_data.value))

    return ";".join(s) + "\n"


def format_message(num, message, options):
    s = [f"{num}. {message.name}"]
    if options.with_defs:
        s.append(f' [{message.type}]')
    s.append('\n')

    if message.type == 'data':
        for field_data in message:
            s.append(f' * {field_data.name}: {field_data.value}')
            if field_data.units:
                s.append(f' [{field_data.units}]')
            s.append('\n')

    s.append('\n')
    return "".join(s)


def parse_args(args=None):
    parser = argparse.ArgumentParser(
        description='Dump .FIT files to various formats',
        epilog='python-fitparse version %s' % fitparse.__version__,
    )
    parser.add_argument('-v', '--verbose', action='count', default=0)
    parser.add_argument(
        '-o', '--output', type=argparse.FileType(mode='w', encoding="utf-8"),
        default="-",
        help='File to output data into (defaults to stdout)',
    )
    parser.add_argument(
        # TODO: csv
        '-t', '--type', choices=('readable', 'json', 'gpx', 'csv', 'xml'), default='readable',
        help='File type to output. (DEFAULT: %(default)s)',
    )
    parser.add_argument(
        '-n', '--name', action='append', help='Message name (or number) to filter',
    )
    parser.add_argument(
        'infile', metavar='FITFILE', type=argparse.FileType(mode='rb'),
        help='Input .FIT file (Use - for stdin)',
    )
    parser.add_argument(
        '--ignore-crc', action='store_const', const=True, help='Some devices seem to write invalid crc\'s, ignore these.'
    )

    options = parser.parse_args(args)

    options.verbose = options.verbose >= 1
    options.with_defs = (options.type == "readable" and options.verbose)
    options.as_dict = (options.type != "readable" and options.verbose)

    return options


class RecordJSONEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, types.GeneratorType):
            return list(obj)
        if isinstance(obj, (datetime.datetime, datetime.time)):
            return obj.isoformat()
        if isinstance(obj, fitparse.DataMessage):
            return {
                "type": obj.name,
                "data": {
                    data.name: data.value for data in obj
                }
            }
        # Fall back to original to raise a TypeError
        return super().default(obj)


def generate_xml(records, filename=None):

    """ generic XML output """

    GPX_TIME_FMT = "%Y-%m-%dT%H:%M:%SZ"  # ISO 8601 format

    records = iter(records)
    s = 0.0
    t_0 = datetime.datetime.utcnow()
    a_i = 0
    a_j = 0
    d_a = 0
    t_i = 0
    t_b = 0
    i_i = []
    hr_i_max = 0

    for message in records:
        if 'unknown' in message.name:
            pass
        else:
            speed = 0.0
            hr = 0
            td = datetime.timedelta(seconds=0)
            strResult = '  <{}>\n'.format(message.name)
            fError = False
            
            for field_data in message:

                if field_data.value == None or 'unknown' in field_data.name:
                    continue
                elif (field_data.name == "timestamp" or field_data.name == "start_time") and type(field_data.value) == datetime.datetime:
                    t = field_data.value.time()
                    td = field_data.value - t_0
                    t_0 = field_data.value
                    if (td.total_seconds() < 0 or td.total_seconds() > 60) and message.name == 'record':
                        strResult += '<!-- error: timedelta {} to large -->\n'.format(td.total_seconds())
                        fError = True
                    strResult += '  <{n} sec="{s}" delta="{d}">{v}</{n}>\n'.format(n=field_data.name, s=(t.hour * 3600 + t.minute * 60 + t.second), d = round(td.total_seconds()), v=field_data.value.strftime(GPX_TIME_FMT))
                elif field_data.name == 'speed':
                    speed = round(field_data.value,1)
                    strResult += '  <{n} unit="{u}">{v}</{n}>\n'.format(n=field_data.name, u=field_data.units, v=speed)
                elif field_data.name == 'heart_rate':
                    hr = round(field_data.value)
                    strResult += '  <{n} unit="{u}">{v}</{n}>\n'.format(n=field_data.name, u=field_data.units, v=hr)
                elif field_data.units == None:
                    strResult += '  <{n}>{v}</{n}>\n'.format(n=field_data.name, v=field_data.value)
                elif field_data.units == 'm':
                    strResult += '  <{n} unit="{u}">{v:.2f}</{n}>\n'.format(n=field_data.name, u=field_data.units, v=field_data.value)
                    if field_data.name == 'altitude':
                        a_i = field_data.value
                elif 'km' in field_data.units:
                    strResult += '  <{n} unit="{u}">{v:.3f}</{n}>\n'.format(n=field_data.name, u=field_data.units, v=field_data.value)
                    if field_data.name == 'distance':
                        s = field_data.value
                else:
                    strResult += '  <{n} unit="{u}">{v:.3f}</{n}>\n'.format(n=field_data.name, u=field_data.units, v=field_data.value)

            strResult += '  </{}>\n'.format(message.name)

            if fError:
                stat_hr.clear()
                stat_hr_intervals.clear()
                stat_speed.clear()
            else:
                # now collect some data for statitistics
                if hr > 40:
                    # add number of seconds, because of variable data rate
                    for i in range(round(td.total_seconds())):
                        stat_hr.append(hr)
                        
                    if hr >= hr_threshold_up or (t_i > 0 and hr >= hr_threshold_down):
                        # count this values
                        t_i += round(td.total_seconds())
                        if a_j > 0:
                            d_a += a_i - a_j
                        a_j = a_i
                        if len(i_i) < 1:
                            # start new interval
                            i_i.append((t.hour * 3600 + t.minute * 60 + t.second))
                            i_i.append(s)
                            hr_i_max = 0
                        if hr > hr_i_max:
                            hr_i_max = hr
                    elif t_i > 0:
                        # block is finished
                        stat_hr_intervals.append(t_i)
                        # end current interval
                        i_i.append((t.hour * 3600 + t.minute * 60 + t.second))
                        i_i.append(s)
                        i_i.append(hr_i_max)
                        i_i.append(d_a)
                        stat_intervals.append(i_i)
                        t_i = 0
                        i_i = []
                        hr_i_max = 0
                        a_j = 0
                        d_a = 0

                    if hr < hr_threshold_break:
                        # count this values
                        t_b += round(td.total_seconds())
                    elif t_b > 0:
                        # block is finished
                        stat_hr_breaks.append(t_b)
                        t_b = 0

                if speed > 0.1:
                    for i in range(round(td.total_seconds())):
                        stat_speed.append(speed)

            yield strResult


def generate_xml_stat():

    """ statistics XML output """

    if len(stat_hr) < 10:
        strResult = '  <!-- no usable data -->'
    else:

        #print(f'info: {stat_intervals}', file=sys.stderr)
        if len(stat_intervals) > 0:
            strTmp = ''
            d_t = 0
            d_s = 0.0
            for i in stat_intervals:
                strTmp += '  <interval t_0="{}" s_0="{:.3f}" t_1="{}" s_1="{:.3f}" hr_max="{}" v="{:.1f}" d_a="{:.0f}"/>\n'.format(i[0], i[1], i[2], i[3], i[4], 3600.0 * (i[3] - i[1]) / (i[2] - i[0]), i[5])
                d_t += i[2] - i[0]
                d_s += i[3] - i[1]
                
            strResult = f'<intervals id="intervals" d_t="{d_t}" d_s="{d_s}">\n{strTmp}</intervals>\n'
            yield strResult
            
        strResult = ''
        a_intervals = np.array(stat_hr_intervals)
        n = len(a_intervals)
        #print(f'info: {stat_hr_intervals}', file=sys.stderr)
        if n > 0:
            # for one dimensional data
            (hist, bin_edges) = np.histogram(a_intervals, bins=np.arange(0,a_intervals.max() + 3 * t_c,t_c))

            v_sum = 0.0
            strResult += '  <hist param="{}" count="{}" sum="{}" norm="{}" min="{:.1f}" max="{:.1f}" hr_1="{}" hr_2="{}">\n'.format('heart_rate_intervals', len(a_intervals), a_intervals.sum(), 'no', a_intervals.min(), a_intervals.max(),hr_threshold_up,hr_threshold_down)
            for i in range(len(bin_edges)-1):
                strResult += '    <c v="{}">{}</c>\n'.format(int(bin_edges[i]), hist[i])
                v_sum += hist[i]
            strResult += '  </hist>\n'

            #print(f'info: {strResult}', file=sys.stderr)
            yield strResult
                    
        strResult = ''
        a_breaks = np.array(stat_hr_breaks)
        n = len(a_breaks)
        #print(f'info: {stat_hr_breaks}', file=sys.stderr)
        if n > 0:
            # for one dimensional data
            (hist, bin_edges) = np.histogram(a_breaks, bins=np.arange(t_c,a_breaks.max() + 3 * t_c,t_c))

            v_sum = 0.0
            strResult += '  <hist param="{}" count="{}" sum="{}" norm="{}" min="{:.1f}" max="{:.1f}" hr_0="{}">\n'.format('heart_rate_breaks', len(a_breaks), a_breaks.sum(), 'no', a_breaks.min(), a_breaks.max(), hr_threshold_break)
            for i in range(len(bin_edges)-1):
                strResult += '    <c v="{}">{}</c>\n'.format(int(bin_edges[i]), hist[i])
                v_sum += hist[i]
            strResult += '  </hist>\n'

            #print(f'info: {strResult}', file=sys.stderr)
            yield strResult
                    
        strResult = ''
        a_hr = np.array(stat_hr)
        n = len(a_hr)
        if n > 10:
            # for one dimensional data
            (hist, bin_edges) = np.histogram(a_hr, bins=np.arange(75,225,5))

            v_sum = 0.0
            strResult += '  <hist param="{}" count="{}" norm="{}" median="{:.1f}" max="{:.1f}">\n'.format('heart_rate', len(a_hr), 'yes', a_hr.mean(), a_hr.max())
            for i in range(len(bin_edges)-1):
                strResult += '    <c v="{}" n="{}" sum="{:.4f}">{:.4f}</c>\n'.format(int(bin_edges[i]), hist[i], 1.0 - v_sum / n, hist[i] / n)
                v_sum += hist[i]
            strResult += '  </hist>\n'

            yield strResult

        strResult = ''
        a_speed = np.array(stat_speed)
        n = len(a_speed)
        if n > 10:
            # for one dimensional data
            (hist, bin_edges) = np.histogram(a_speed, bins=np.arange(0,75,1))

            v_sum = 0.0
            strResult += '  <hist param="{}" count="{}" norm="{}" median="{:.1f}" max="{:.1f}">\n'.format('speed', len(a_speed), 'yes', a_speed.mean(), a_speed.max())
            for i in range(len(bin_edges)-1):
                strResult += '    <c v="{}" n="{}" sum="{:.4f}">{:.4f}</c>\n'.format(int(bin_edges[i]), hist[i], 1.0 - v_sum / n, hist[i] / n)
                v_sum += hist[i]
            strResult += '  </hist>\n'
        
            yield strResult

        
def generate_gpx(records, filename=None):
    # TODO: Use xml.etree.ElementTree ?

    GPX_TIME_FMT = "%Y-%m-%dT%H:%M:%SZ"  # ISO 8601 format

    records = iter(records)

    # header + open tags
    yield '<?xml version="1.0"?>\n'
    yield '<gpx xmlns="http://www.topografix.com/GPX/1/1" version="1.1" creator="python-fitparse (fitdump)" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.topografix.com/GPX/1/1 http://www.topografix.com/GPX/1/1/gpx.xsd">\n'
    yield ' <metadata>\n'

    # file creation time (if a file_id record exists)
    first_record = []
    for message in records:
        if message.name == "file_id":
            for field_data in message:
                if field_data.name == "time_created" and type(field_data.value) == datetime.datetime:
                    yield f'  <time>{field_data.value.strftime(GPX_TIME_FMT)}</time>\n'
                    break
            else:
                # No time found in the fields, check next record
                continue
            break
        elif message.name == "record":
            first_record.append(message)
            break

    if filename:
        yield f'  <src>{filename}</src>\n'

    yield ' </metadata>\n'
    yield ' <trk>\n'

    if filename:
        yield f'  <name>{filename}</name>\n'

    yield '  <trkseg>\n'

    # track points
    for message in itertools.chain(first_record, records):
        if message.name != "record":
            continue

        trkpt = {}

        # TODO: support more data types (heart rate, cadence, etc)
        for field_data in message:
            if field_data.name == "position_lat":
                # Units are decimal degrees
                trkpt["lat"] = field_data.value
            elif field_data.name == "position_long":
                # Units are decimal degrees
                trkpt["lon"] = field_data.value
            elif field_data.name == "enhanced_altitude":
                # Units are m
                trkpt["ele"] = field_data.value
            elif field_data.name == "timestamp" and type(field_data.value) == datetime.datetime:
                trkpt["time"] = field_data.value.strftime(GPX_TIME_FMT)
            elif field_data.name == "enhanced_speed" and type(field_data.value) == float:
                # convert from km/h to m/s
                trkpt["speed"] = field_data.value / 3.6

        # Add trackpoint
        if "lat" in trkpt and "lon" in trkpt:
            yield '   <trkpt lat="{lat}" lon="{lon}">\n'.format(**trkpt)
            if "ele" in trkpt:
                yield '    <ele>{ele}</ele>\n'.format(**trkpt)
            if "time" in trkpt:
                yield '    <time>{time}</time>\n'.format(**trkpt)
            if "speed" in trkpt:
                yield '    <speed>{speed}</speed>\n'.format(**trkpt)
            yield '   </trkpt>\n'

    # close tags
    yield '  </trkseg>\n'
    yield ' </trk>\n'
    yield '</gpx>\n'


def main(args=None):
    options = parse_args(args)

    fitfile = fitparse.UncachedFitFile(
        options.infile,
        data_processor=fitparse.StandardUnitsDataProcessor(),
        check_crc=not(options.ignore_crc),
    )
    records = fitfile.get_messages(
        name=options.name,
        with_definitions=options.with_defs,
        as_dict=options.as_dict
    )

    try:
        if options.type == "json":
            json.dump(records, fp=options.output, cls=RecordJSONEncoder)
        elif options.type == "readable":
            options.output.writelines(
                format_message(n, record, options) for n, record in enumerate(records, 1)
            )
        elif options.type == "csv":
            options.output.writelines(
                format_csv(n, record, options) for n, record in enumerate(records, 1)
            )
        elif options.type == "xml":
            # header + open tags
            options.output.writelines('<?xml version="1.0"?>\n')
            #options.output.writelines('<?xml-stylesheet type="text/xsl" href="fit2html.xsl"?>\n')
    
            filename = getattr(options.infile, "name")
            if filename:
                options.output.writelines('<fit src="{}">\n'.format(os.path.basename(filename)))
            else:
                options.output.writelines('<fit>\n')

            options.output.writelines(generate_xml(records, filename))
            options.output.writelines(generate_xml_stat())
            options.output.writelines('</fit>\n')
        elif options.type == "gpx":
            filename = getattr(options.infile, "name")
            if filename:
                filename = os.path.basename(filename)
            options.output.writelines(generate_gpx(records, filename))

    finally:
        try:
            options.output.close()
        except OSError:
            pass

if __name__ == '__main__':
    try:
        main()
    except BrokenPipeError:
        pass
